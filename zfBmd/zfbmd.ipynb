{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a512dd5-4167-4cbd-bac9-05e9f0abf369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/degn400/Desktop/Git_Repos/srpAnalytics/zfBmd\n",
      "/Users/degn400/Desktop/Git_Repos/srpAnalytics/zfBmd\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os, sys, time\n",
    "import argparse\n",
    "import tarfile\n",
    "import re\n",
    "\n",
    "##impor  BMD files from directory\n",
    "##TODO: combine bMD processing to single file, combine LPR processing to single file\n",
    "import bmd_analysis_morpho as bmd\n",
    "import bmd_analysis_LPR_7_PAH_t0_t239 as bmd_LPR\n",
    "import format_LPR_input as format_LPR\n",
    "import format_morpho_input as format_morpho"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729f24d2-951c-4317-83b7-40b14fdbc35e",
   "metadata": {},
   "source": [
    "# Journey that a single morpho file takes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75907b52-1d5c-4e5c-b7ff-2e14c7348f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfiles = './test_files/7_PAH_zf_morphology_data_2020NOV11_tall_3756.csv'\n",
    "\n",
    "morpho_input_csv_file_name_wide = mfiles.split(\"/\")[-1] + \"_wide_DNC_0_\"+ \"fd\" + \".csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372ddb3f-117b-4bca-b2bd-2ab46bad7244",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_morph = pd.read_csv(mfiles, header = 0)\n",
    "\n",
    "# Keep onloy relevant columns\n",
    "columns_to_keep = ['chemical.id', 'conc', 'plate.id', 'well', 'endpoint', 'value']\n",
    "df_morph_select = df_morph.loc[:,columns_to_keep]\n",
    "\n",
    "# Convert numerics to strings \n",
    "df_morph_select['plate.id'] = df_morph_select['plate.id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60318f7-3077-4844-9b2b-f4e96780cf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_morph = pd.read_csv(mfiles, header = 0)\n",
    "relevant_columns = ['chemical.id', 'conc', 'plate.id', 'well', 'endpoint', 'value']\n",
    "all(col in df_morph.columns for col in relevant_columns) == False\n",
    "print(\"The input file\", mfiles, \"must have the columns:\", ', '.join(relevant_columns)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1443b120-a45a-47f3-a557-4d30972a31cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_morph_select.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9d8432-22fd-46cb-aa90-9573b0e3e4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reformatted = pd.DataFrame()\n",
    "\n",
    "for chemical_index in pd.unique(df_morph['chemical.id']):\n",
    "\n",
    "    print(\"chemical_index:\" + str(chemical_index))\n",
    "    #total_number_of_unique_chemicals += 1\n",
    "    morph_data_chemical = df_morph_select.loc[df_morph['chemical.id'] == chemical_index,:]\n",
    "\n",
    "    # Append chemical_plate_well as a unique identifier\n",
    "    morph_data_chemical.insert(0, 'chemical_plate_well', morph_data_chemical.loc[:,['chemical.id','plate.id', 'well']].apply(lambda x: '_'.join(x.map(str)), axis = 1))\n",
    "\n",
    "    for cpw in np.unique(morph_data_chemical.chemical_plate_well):\n",
    "        #total_number_of_chemical_plate_well += 1\n",
    "        temp_df = morph_data_chemical.loc[morph_data_chemical.chemical_plate_well == cpw,:]\n",
    "\n",
    "        temp_df_grouped = temp_df.groupby(['chemical.id', 'plate.id', 'well'])\n",
    "        for name, group in temp_df_grouped:\n",
    "\n",
    "            ## JUSTIFICATION: 7 PAH dataset doesn't have \"BRAI\" endpoint.\n",
    "            ## On the other hand, extracts/phase I,II have \"BRAI\" endpoint.\n",
    "            if 'BRAI' not in temp_df.endpoint.values: # as 7 PAH\n",
    "                try:\n",
    "                    #            if(len(group.endpoint) == 14):\n",
    "                    temp = pd.DataFrame( {\n",
    "                        'chemical.id': pd.unique(temp_df['chemical.id']),\n",
    "                        'plate.id': pd.unique(temp_df['plate.id']),\n",
    "                        'well': pd.unique(temp_df['well']),\n",
    "                        'chemical_plate_well': pd.unique(temp_df['chemical_plate_well']),\n",
    "                        'conc': pd.unique(temp_df['conc']),\n",
    "                        'AXIS': temp_df.value[temp_df.endpoint == 'AXIS'].values,\n",
    "                        'BRN_': temp_df.value[temp_df.endpoint == 'BRN_'].values,\n",
    "                        'CRAN': temp_df.value[temp_df.endpoint == 'CRAN'].values,\n",
    "                        'DNC_': temp_df.value[temp_df.endpoint == 'DNC_'].values,\n",
    "                        'DP24': temp_df.value[temp_df.endpoint == 'DP24'].values,\n",
    "                        'EDEM': temp_df.value[temp_df.endpoint == 'EDEM'].values,\n",
    "                        'LTRK': temp_df.value[temp_df.endpoint == 'LTRK'].values,\n",
    "                        'MO24': temp_df.value[temp_df.endpoint == 'MO24'].values,\n",
    "                        'MORT': temp_df.value[temp_df.endpoint == 'MORT'].values,\n",
    "                        'MUSC': temp_df.value[temp_df.endpoint == 'MUSC'].values,\n",
    "                        'NC__': temp_df.value[temp_df.endpoint == 'NC__'].values,\n",
    "                        'SKIN': temp_df.value[temp_df.endpoint == 'SKIN'].values,\n",
    "                        'SM24': temp_df.value[temp_df.endpoint == 'SM24'].values,\n",
    "                        'TCHR': temp_df.value[temp_df.endpoint == 'TCHR'].values,\n",
    "                    }  )\n",
    "                    df_reformatted = pd.concat([df_reformatted, temp])\n",
    "                except:\n",
    "                    print (\"len(group.endpoint) != 14\")\n",
    "                    print (\"chemical_plate_well:\" + str(cpw))\n",
    "            else: #as extracts\n",
    "                temp = pd.DataFrame(\n",
    "                    {\n",
    "                    'chemical.id': pd.unique(temp_df['chemical.id']),\n",
    "                    'plate.id': pd.unique(temp_df['plate.id']),\n",
    "                    'well': pd.unique(temp_df['well']),\n",
    "                    'chemical_plate_well': pd.unique(temp_df['chemical_plate_well']),\n",
    "                    'conc': pd.unique(temp_df['conc']),\n",
    "                    'AXIS': temp_df.value[temp_df.endpoint == 'AXIS'].values,\n",
    "                    'BRAI': temp_df.value[temp_df.endpoint == 'BRAI'].values,\n",
    "                    'CFIN': temp_df.value[temp_df.endpoint == 'CFIN'].values,\n",
    "                    'CIRC': temp_df.value[temp_df.endpoint == 'CIRC'].values,\n",
    "                    'DNC_': temp_df.value[temp_df.endpoint == 'DNC_'].values,\n",
    "                    'DP24': temp_df.value[temp_df.endpoint == 'DP24'].values,\n",
    "                    'EYE_': temp_df.value[temp_df.endpoint == 'EYE_'].values,\n",
    "                    'JAW_': temp_df.value[temp_df.endpoint == 'JAW_'].values,\n",
    "                    'MO24': temp_df.value[temp_df.endpoint == 'MO24'].values,\n",
    "                    'MORT': temp_df.value[temp_df.endpoint == 'MORT'].values,\n",
    "                    'NC24': temp_df.value[temp_df.endpoint == 'NC24'].values,\n",
    "                    'NC__': temp_df.value[temp_df.endpoint == 'NC__'].values,\n",
    "                    'OTIC': temp_df.value[temp_df.endpoint == 'OTIC'].values,\n",
    "                    'PE__': temp_df.value[temp_df.endpoint == 'PE__'].values,\n",
    "                    'PFIN': temp_df.value[temp_df.endpoint == 'PFIN'].values,\n",
    "                    'PIG_': temp_df.value[temp_df.endpoint == 'PIG_'].values,\n",
    "                    'SM24': temp_df.value[temp_df.endpoint == 'SM24'].values,\n",
    "                    'SNOU': temp_df.value[temp_df.endpoint == 'SNOU'].values,\n",
    "                    'SOMI': temp_df.value[temp_df.endpoint == 'SOMI'].values,\n",
    "                    'SWIM': temp_df.value[temp_df.endpoint == 'SWIM'].values,\n",
    "                    'TRUN': temp_df.value[temp_df.endpoint == 'TRUN'].values,\n",
    "                    'TR__': temp_df.value[temp_df.endpoint == 'TR__'].values,\n",
    "                    'YSE_': temp_df.value[temp_df.endpoint == 'YSE_'].values,\n",
    "                    })\n",
    "                df_reformatted = pd.concat([df_reformatted, temp])\n",
    "#print (\"total_number_of_unique_chemicals:\" + str(total_number_of_unique_chemicals))\n",
    "#print (\"total_number_of_chemical_plate_well:\" + str(total_number_of_chemical_plate_well))\n",
    "#end_time = time.time()\n",
    "#time_took = str(round((end_time-start_time), 1)) + \" seconds\"\n",
    "#print (\"Done, it took:\"+str(time_took))\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "print (df_reformatted.head())\n",
    "#print (\"df_reformatted.shape:\" + str(df_reformatted.shape)) #(288, 19)\n",
    "\n",
    "df_reformatted_DNC_0 = pd.DataFrame()\n",
    "\n",
    "df_reformatted_DNC_0 = df_reformatted.loc[df_reformatted['DNC_'] == 0.0]\n",
    "print (\"df_reformatted_DNC_0.shape:\" + str(df_reformatted_DNC_0.shape)) #(287, 19)\n",
    "\n",
    "df_reformatted_DNC_0.to_csv(\"./Reformatted.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb454de-dd3b-4876-9789-e0e85ef3ed4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot long format table wider, and sum up the ones \n",
    "pivot_wider = df_morph_select.pivot_table(index = ['chemical.id', 'plate.id', 'well', 'conc'], columns = ['endpoint'], values = ['value'], aggfunc = 'first')\n",
    "\n",
    "# Convert to a clean pandas dataframe \n",
    "pivot_wider = pd.DataFrame(pivot_wider.to_records())\n",
    "\n",
    "# Clean up the column names \n",
    "new_colnames = []\n",
    "\n",
    "# Fix column names with the extra 'value' annotation. Otherwise, ignore.\n",
    "for name in pivot_wider.columns:\n",
    "    if \"value\" in name:\n",
    "        new_colnames.append(re.sub(\"\\\\(value,|\\\\)\", \"\", re.sub(\"'\", \"\", name)).strip())\n",
    "    else:\n",
    "        new_colnames.append(name)\n",
    "\n",
    "# Rename columns\n",
    "pivot_wider = pivot_wider.set_axis(new_colnames, axis = 1, inplace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc953e2-e8d5-4558-a49a-98de40fafbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_columns = ['chemical.id', 'conc', 'plate.id', 'well', 'endpoint', 'value']\n",
    "for x in ['AXIS', 'BRN_', 'CRAN', 'DNC_', 'DP24', 'EDEM', 'LTRK', 'MO24', 'MORT', 'MUSC', 'NC__', 'SKIN','SM24', 'TCHR']:\n",
    "    relevant_columns.append(x)\n",
    "relevant_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41db4a91-503b-4ad7-be60-807f65e1f977",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_morph.pivot_table(index = ['chemical.id', 'plate.id', 'well', 'conc'], columns = ['endpoint'], \n",
    "                                       values = ['value'], aggfunc = 'first')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2e4f21-28d5-4a74-9765-59f998a53efe",
   "metadata": {},
   "source": [
    "# Morpho Step 1: Format File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "89504507-a9d9-44f4-aaf7-717ba91aa48d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (449188124.py, line 109)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/wn/j99mzl110154njzrzjdvtdjdkp556l/T/ipykernel_45642/449188124.py\"\u001b[0;36m, line \u001b[0;32m109\u001b[0m\n\u001b[0;31m    chemical_groups =\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# This is the format_morpho_input function\n",
    "\n",
    "##############################################\n",
    "## READ FILE AND SUBSET TO RELEVANT COLUMNS ##\n",
    "##############################################\n",
    "\n",
    "# Read morphology file \n",
    "df_morph = pd.read_csv('./test_files/7_PAH_zf_morphology_data_2020NOV11_tall_3756.csv', header = 0)\n",
    "\n",
    "# List relevant column names\n",
    "relevant_columns = ['chemical.id', 'conc', 'plate.id', 'well', 'endpoint', 'value']\n",
    "\n",
    "# The input file must absolutely have these columns, no exceptions \n",
    "if all(col in df_morph.columns for col in relevant_columns) == False:\n",
    "    sys.exit(print(\"The input file\", mfiles, \"must have the columns:\", ', '.join(relevant_columns)))\n",
    "\n",
    "# Keep only relevant columns\n",
    "df_morph = df_morph.loc[:,relevant_columns]\n",
    "\n",
    "###########################################\n",
    "## CALCULATE VARIABLES FOR DOSE RESPONSE ##\n",
    "###########################################\n",
    "\n",
    "# Create groups of each chemical id, concentration, and plate id\n",
    "plate_groups = df_morph.drop([\"well\"], 1).groupby(by = [\"chemical.id\", \"conc\", \"plate.id\", \"endpoint\"], as_index = False)\n",
    "\n",
    "# Get the number of samples per group\n",
    "num_tot_samples = plate_groups.size().rename(columns = {\"size\": \"num.tot\"})\n",
    "\n",
    "# Get the number of non-na samples per groups\n",
    "num_nonna = plate_groups.count().rename(columns = {\"value\": \"num.nonna\"})\n",
    "\n",
    "# Get the number affected\n",
    "num_affected = plate_groups.sum().rename(columns = {\"value\": \"num.affected\"})\n",
    "\n",
    "# Merge to create missingness dataframe\n",
    "plate_groups = pd.merge(pd.merge(num_tot_samples, num_nonna), num_affected)\n",
    "\n",
    "# Create IDs of chemical.id, plate.id, and endpoint in plate_groups \n",
    "ids = []\n",
    "for row in range(len(plate_groups)):\n",
    "    ids.append(str(plate_groups[\"chemical.id\"][row]) + \" \" + str(plate_groups[\"plate.id\"][row]) + \" \" + str(plate_groups[\"endpoint\"][row]))\n",
    "plate_groups[\"ids\"] = ids\n",
    "\n",
    "#####################################################################\n",
    "## REMOVE VARIABLES WITH HIGH MISSINGNESS IN BASELINE MEASUREMENTS ##\n",
    "#####################################################################\n",
    "\n",
    "# Identify 0 (baseline) concentrations with high missingness (greater than 50% missing or less than 50% non-missing)\n",
    "missingness = plate_groups.loc[plate_groups[\"conc\"] == 0]\n",
    "missingness[\"keep\"] = missingness[\"num.nonna\"] / missingness[\"num.tot\"] > 0.5 # TODO: Add a report of what was removed --> txt file \"nothing removed\"\n",
    "\n",
    "# Identify plates to keep \n",
    "tokeep = missingness.loc[missingness[\"keep\"]][\"ids\"].tolist()\n",
    "plate_groups = plate_groups[plate_groups[\"ids\"].isin(tokeep)]\n",
    "\n",
    "# Stop if everything gets removed\n",
    "if len(plate_groups) == 0:\n",
    "    sys.exit(\"Everything was removed with the 50% missingness filter\")\n",
    "\n",
    "#######################################\n",
    "## REGROUP WITHOUT PLATE IDS AND SUM ##\n",
    "#######################################\n",
    "\n",
    "# First, remove plate.id and ids column\n",
    "chemical_groups = plate_groups.drop(columns = [\"plate.id\", \"ids\"])\n",
    "\n",
    "# Group by chemical.id, concentration, and endpoint. Then, sum the results. \n",
    "chemical_groups = chemical_groups.groupby(by = [\"chemical.id\", \"conc\", \"endpoint\"]).sum().reset_index()\n",
    "\n",
    "##################################\n",
    "## SUBSET TO RELEVANT ENDPOINTS ##\n",
    "##################################\n",
    "\n",
    "# List the relevant endpoints, which is different for BRAIN samples  \n",
    "if \"BRAI\" in list(chemical_groups[\"endpoint\"].unique()):\n",
    "    relevant_endpoints = ['AXIS', 'BRAI', 'CFIN', 'CIRC', 'DNC_', 'DP24', 'EYE_', 'JAW_', 'MO24', \n",
    "                          'MORT', 'NC24', 'NC__', 'OTIC', 'PE__', 'PFIN', 'PIG_', 'SM24', 'SNOU', \n",
    "                          'SOMI', 'SWIM', 'TRUN', 'TR__', 'YSE_']\n",
    "else:\n",
    "    relevant_endpoints = ['AXIS', 'BRN_', 'CRAN', 'DNC_', 'DP24', 'EDEM', 'LTRK', 'MO24', 'MORT', \n",
    "                          'MUSC', 'NC__', 'SKIN','SM24', 'TCHR']\n",
    "    \n",
    "# Subset down to the relevant endpoints \n",
    "chemical_groups = chemical_groups[chemical_groups[\"endpoint\"].isin(relevant_endpoints)]\n",
    "\n",
    "###########################\n",
    "## ADD MISSING ENDPOINTS ##\n",
    "###########################\n",
    "\n",
    "def new_endpoint(endpoints, new_name):\n",
    "    \"\"\"\n",
    "    Generate a new endpoint which is a sum of existing endpoints.\n",
    "    \n",
    "    Attributes\n",
    "    ----\n",
    "    endpoints: A list of column names, as strings, to sum.\n",
    "    new_name: The name of the new endpoint. \n",
    "    \n",
    "    \"\"\"\n",
    "    sub_df = chemical_groups[chemical_groups[\"endpoint\"].isin(endpoints)]\n",
    "    sub_df[\"endpoint\"] = new_name\n",
    "    sub_df = sub_df.groupby(by = [\"chemical.id\", \"conc\", \"endpoint\"]).sum().reset_index()\n",
    "    return(sub_df)\n",
    "\n",
    "# New endpoints to add is a smaller list if the sample is not from BRAIN\n",
    "if \"BRAI\" in list(chemical_groups[\"endpoint\"].unique()):\n",
    "    \n",
    "    chemical_groups = pd.concat(\n",
    "        [new_endpoint(['MO24','DP24','SM24','NC24'], 'ANY24'),\n",
    "         new_endpoint(['MORT', 'YSE_', 'AXIS', 'EYE_', 'SNOU', 'JAW_', 'OTIC', 'PE__', 'BRAI', \n",
    "                      'SOMI', 'PFIN', 'CFIN', 'PIG_', 'CIRC', 'TRUN', 'SWIM', 'NC__', 'TR__', \n",
    "                      'ANY24'], 'ANY120'),\n",
    "         new_endpoint(['MO24','MORT'], 'TOT_MORT'),\n",
    "         new_endpoint(['DP24','SM24','NC24', 'YSE_', 'AXIS', 'EYE_', 'SNOU', 'JAW_', 'OTIC', 'PE__', \n",
    "                      'BRAI', 'SOMI', 'PFIN', 'CFIN', 'PIG_', 'CIRC','TRUN', 'SWIM', 'NC__', 'TR__'], 'ALL_BUT_MORT'),\n",
    "         new_endpoint(['BRAI','OTIC','PFIN'], 'BRN_'),\n",
    "         new_endpoint(['EYE_', 'SNOU', 'JAW_'], 'CRAN'),\n",
    "         new_endpoint(['YSE_','PE__'], 'EDEM'),\n",
    "         new_endpoint(['TRUN','CFIN'], 'LTRK'),\n",
    "         new_endpoint(['CIRC','SWIM','SOMI'], 'MUSC'),\n",
    "         new_endpoint(['PIG_'], 'SKIN'),\n",
    "         new_endpoint(['TR__'], 'TCHR'),\n",
    "         chemical_groups]\n",
    "    )\n",
    "    \n",
    "else:\n",
    "    \n",
    "    chemical_groups = pd.concat(\n",
    "\n",
    "        # 1. Add any effect at 24hrs (combination of MO24, DP24 and SM24) \n",
    "        [new_endpoint(['MO24','DP24','SM24'], 'ANY24'),\n",
    "\n",
    "        # 2. Any effect within 5 days (combination of all measurements at both time points)\n",
    "        new_endpoint(['AXIS', 'BRN_', 'CRAN', 'EDEM', 'LTRK', 'MORT', 'MUSC', 'NC__', 'SKIN', 'TCHR', 'ANY24'], 'ANY120'),\n",
    "\n",
    "        # 3. Total mortality (MO24 + MORT) \n",
    "        new_endpoint(['MO24','MORT'], 'TOT_MORT'),\n",
    "\n",
    "        # 4. Any effect except mortality (#2 minus MO24 and MORT)\n",
    "        new_endpoint(['AXIS', 'BRN_', 'CRAN', 'DP24', 'EDEM', 'LTRK', 'MUSC', 'NC__', 'SKIN', 'SM24', 'TCHR'], 'ALL_BUT_MORT'),\n",
    "        \n",
    "        # Add original dataframe\n",
    "        chemical_groups]\n",
    "    )\n",
    "    \n",
    "############################\n",
    "## RETURN FORMATTED TABLE ##\n",
    "############################\n",
    "chemical_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1d3973-fa45-454e-93d3-b86e2a94c806",
   "metadata": {},
   "source": [
    "# Format Step 2: Generate Dose Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe17e25-948b-4d36-a7ce-d5473814c7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the generate dose response function\n",
    "\n",
    "#################################################\n",
    "## IDENTIFY MEASUREMENTS WITH HIGH MISSINGNESS ## \n",
    "#################################################\n",
    "\n",
    "# Create groups of each chemical id, concentration, and plate id\n",
    "missingness_test = pivot_wider.drop([\"well\"], 1).groupby(by = [\"chemical.id\", \"conc\", \"plate.id\"], as_index = False)\n",
    "\n",
    "# Get the number of samples per group\n",
    "tot_num_samples = missingness_test.size()\n",
    "\n",
    "# Get the number of non-na samples per groups\n",
    "nonna = missingness_test.count()\n",
    "\n",
    "# Get the endpoint columns\n",
    "colnames = list(pivot_wider.columns)\n",
    "endpoints = [x for x in colnames if x not in [\"chemical.id\", \"conc\", \"plate.id\", \"well\"]]\n",
    "\n",
    "# Create a list of chemical id, concentations, plated id, and endpoints to remove\n",
    "removals = list()\n",
    "\n",
    "# Determine the groups and endpoints that have more than 50% missingness \n",
    "for row in range(len(tot_num_samples)):\n",
    "    chemid = tot_num_samples.at[row, \"chemical.id\"]\n",
    "    conc = tot_num_samples.at[row, \"conc\"]\n",
    "    plateid = tot_num_samples.at[row, \"plate.id\"]\n",
    "    threshold = tot_num_samples.at[row, \"size\"] * 0.5\n",
    "    remove = nonna.loc[(nonna[\"chemical.id\"] == chemid) & \n",
    "                    (nonna[\"conc\"] == conc) &\n",
    "                    (nonna[\"plate.id\"] == plateid), endpoints] < threshold\n",
    "    if any(remove == False) and row in [3,5,7]:\n",
    "        missing_endpoints = list(remove[remove == False].columns)\n",
    "        removals.append(pd.DataFrame({\"chemical.id\": chemid, \"conc\": conc, \"plate.id\": plateid, \"missing_endpoints\": missing_endpoints}))\n",
    "\n",
    "# Generate one dataframe of removals \n",
    "removals = pd.concat(removals)\n",
    " \n",
    "# Set all of these values to NA \n",
    "pivot_wider.loc[(pivot_wider[\"chemical.id\"].isin(removals[\"chemical.id\"].unique().tolist())) &\n",
    "                (pivot_wider[\"conc\"].isin(removals[\"conc\"].unique().tolist())) &\n",
    "                (pivot_wider[\"plate.id\"].isin(removals[\"plate.id\"].unique().tolist()))\n",
    "               ]\n",
    "pivot_wider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37f08c9-1e30-484f-9efd-a44d9cdff516",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84255ad5-b9a9-422b-ac55-474c6a64f7a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get NA counts \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed37af6-7a69-4041-a8a5-1535fef19f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_embryos = pivot_wider.drop([\"plate.id\", \"well\"], 1).groupby(by = [\"chemical.id\", \"conc\"], dropna = True).count()\n",
    "num_embryos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f157c975-41db-41b0-951c-9b242c828186",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_affected = pivot_wider.drop(\"plate.id\", 1).groupby(by = [\"chemical.id\", \"conc\"], dropna = True).sum()\n",
    "num_affected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e2f3da-2961-4353-98a2-cb91c307ef16",
   "metadata": {},
   "outputs": [],
   "source": [
    "frac_affected = num_affected / num_embryos\n",
    "frac_affected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429c72f9-5c80-4d45-b9dc-13e88a9e2259",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a673cc-8529-4590-9288-2c0d71fb7330",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_wells = pivot_wider.drop(\"plate.id\", 1).groupby(by = [\"chemical.id\", \"conc\"]).size()\n",
    "tot_wells"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
