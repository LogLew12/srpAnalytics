{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data set: # mac       - phase III - LPR\n",
    "# goal:     see y trends\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os, random, shutil, time\n",
    "import seaborn as sns\n",
    "from statannot import add_stat_annotation\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "\n",
    "#mac\n",
    "util_path = \"/Users/kimd999/research/script_not_in_dropbox/srpAnalytics/analysis/latest/util\"\n",
    "\n",
    "#constance\n",
    "'''args = sys.argv[0:]\n",
    "py_file = args[0]\n",
    "py_file_wo_path = os.path.basename(py_file)\n",
    "\n",
    "code_location = os.path.dirname(os.path.abspath(py_file))\n",
    "index_of_latest = code_location.index('latest')\n",
    "util_path = os.path.join(code_location[:index_of_latest], \"latest\", \"util\")\n",
    "'''\n",
    "\n",
    "sys.path.insert(0, util_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_dir = os.getcwd()\n",
    "print (starting_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mac       - phase III - LPR - 240 timepoints - full\n",
    "complete_file_path = '/Users/kimd999/research/projects/toxicity/per_each_data/phase_III/input/behavior/LPR/wide/full/Tanguay_Phase_3_zf_LPR_data_PNNL_2021MAR23_full_w_240_timepoints_wide_full.csv'\n",
    "\n",
    "df_lpr = pd.read_csv(complete_file_path, header = 0)\n",
    "display(df_lpr.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess chemical ids\n",
    "df_lpr['chemical.id'] = (df_lpr['chemical.id'].values).astype(int)\n",
    "df_lpr['chemical.id'] = (df_lpr['chemical.id'].values).astype(str)\n",
    "\n",
    "display(len(np.unique(df_lpr['chemical.id'])))\n",
    "#display(np.unique(df_lpr['chemical.id']))\n",
    "#display(df_lpr.head())\n",
    "#display(df_lpr.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess plate ids\n",
    "df_lpr['plate.id'] = (df_lpr['plate.id'].values).astype(int)\n",
    "df_lpr['plate.id'] = (df_lpr['plate.id'].values).astype(str)\n",
    "\n",
    "display(len(np.unique(df_lpr['plate.id'])))\n",
    "#display(np.unique(df_lpr['plate.id']))\n",
    "display(df_lpr.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load morphological data for filtering wells that have dead fish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mac       - phase III - morpho - full\n",
    "morph_data_file_complete_path = '/Users/kimd999/research/projects/toxicity/per_each_data/phase_III/input/morpho/full/wide/Tanguay_Phase_3_zf_morphology_data_PNNL_2021MAR23_full_w_all_endpoints.csv'\n",
    "\n",
    "df_morph = pd.read_csv(morph_data_file_complete_path, header = 0)\n",
    "display(df_morph.head())\n",
    "display(len(df_morph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goal of this box \n",
    "# -> (in df_lpr) leave only rows with non 1 and NA MORT\n",
    "\n",
    "# Running time\n",
    "# 13 seconds took for 215 chemicals\n",
    "\n",
    "# 1. Append additional identifier column (Plate_Well value) to lpr and morphology data\n",
    "# 2. Find rows in morphology data for which MORT end-point is not 1 or NA\n",
    "# 3. Using Plate_Well values, find corresponding rows in lpr data to filter the data\n",
    "\n",
    "# (ref)\n",
    "# '/Users/kimd999/research/projects/toxicity/per_each_data/phase_I_II/input/LPR/latest/after_merging/tall/bifurcated/344_zf_LPR_data_phase_1_2_2020JUNE25_updated_plate_id_for_TX_tall_fixed_merged_full_240_timepoints_cpw_added.csv'\n",
    "# cpw added here already to save 23 minutes\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "df_lpr['Chemical_Plate_WELL'] = df_lpr[['chemical.id','plate.id', 'well']].apply(lambda x: '_'.join(x.map(str)), axis = 1)\n",
    "# used to take few minutes, but in 5/9/2021, it takes 23 minutes\n",
    "\n",
    "display(df_lpr.head())\n",
    "\n",
    "\n",
    "df_morph['Chemical_Plate_WELL'] = df_morph[['chemical.id','plate.id', 'well']].apply(lambda x: '_'.join(x.map(str)), axis = 1)\n",
    "#display(df_morph.head())\n",
    "#print(\"df_morph.shape:\" + str(df_morph.shape)) # (69395, 29)\n",
    "\n",
    "df_morpho_nonna_plate_well = df_morph.Chemical_Plate_WELL[~((df_morph.MORT == 1) | (df_morph.MORT.isnull()))]\n",
    "#display(df_morpho_nonna_plate_well.head())\n",
    "#print(\"df_morpho_nonna_plate_well.shape:\" + str(df_morpho_nonna_plate_well.shape)) # (57558,)\n",
    "\n",
    "df_lpr_filtered = df_lpr.loc[df_lpr['Chemical_Plate_WELL'].isin(list(df_morpho_nonna_plate_well.values))]\n",
    "\n",
    "#display(df_morpho_nonna_plate_well[0:5])\n",
    "#display(df_lpr.Chemical_Plate_WELL[0:5])\n",
    "\n",
    "end_time = time.time()\n",
    "time_took = str(round((end_time-start_time), 1)) + \" seconds\"\n",
    "print (\"Done, it took:\"+str(time_took)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\ndf_lpr.shape:\" + str(df_lpr.shape))\n",
    "\n",
    "print(\"df_lpr_filtered.shape:\"+str(df_lpr_filtered.shape) + \"\\n\") \n",
    "display('df_lpr_filtered.head()',df_lpr_filtered.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Goal] \n",
    "# Convert time resolution to minutes (if applicable)\n",
    "# For LPR, 240 timepoints -> 24 timepoints\n",
    "# Create a new dataframe for storing lpr data in the new time-scale (minutes)\n",
    "# The new dataframe contains the same basic row identifier fields\n",
    "\n",
    "# Running time\n",
    "# -> 0.5 seconds for 1 chemical\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "df_lpr_min = df_lpr_filtered[['chemical.id', 'conc', 'plate.id', 'well']]\n",
    "\n",
    "\n",
    "time_index_sec_start = 5\n",
    "ori_max_time_index_sec   = 240 # from t0 to t239\n",
    "\n",
    "#report = True\n",
    "report = False\n",
    "\n",
    "interval = \"1 min\"\n",
    "#interval = \"30 sec\"\n",
    "#interval = \"12 sec\"\n",
    "print (\"interval:\" + str(interval))\n",
    "\n",
    "print (\"(before transforming for \" + str(interval) + \"), df_lpr_min.shape:\" + str(df_lpr_min.shape))\n",
    "\n",
    "if (interval == \"1 min\"):\n",
    "    group_size = 10 # (10 X 6 sec/sample = 1 min/sample)\n",
    "elif (interval == \"30 sec\"):\n",
    "    group_size = 5 # (5 X 6 sec/sample = 1 min/sample)\n",
    "else: # interval = \"12 sec\"\n",
    "    group_size = 2 # (2 X 6 sec/sample = 1 min/sample)\n",
    "\n",
    "num_time_points = 0\n",
    "for time_index in range(int(ori_max_time_index_sec / group_size)):\n",
    "    num_time_points += 1\n",
    "    start_index = time_index_sec_start + group_size * time_index\n",
    "    end_index = start_index + group_size\n",
    "    if (report):\n",
    "        print (\"\\ntime_index:\" + str(time_index))\n",
    "        print (\"start_index:\"  + str(start_index))\n",
    "        print (\"end_index:\"    + str(end_index))\n",
    "        \n",
    "    df_lpr_min_in_this_time_index = pd.DataFrame(np.sum(df_lpr_filtered.iloc[:,start_index:end_index], axis = 1))\n",
    "    #if (report):\n",
    "        # print (\"df_lpr_min_in_this_time_index.shape:\\n\" + str(df_lpr_min_in_this_time_index.shape))\n",
    "        # display(df_lpr_min_in_this_time_index.head())\n",
    "        # display(df_lpr_min_in_this_time_index.tail())\n",
    "        # display(df_lpr_min_in_this_time_index)\n",
    "    \n",
    "    df_lpr_min_in_this_time_index.columns = ['t' + str(time_index)]\n",
    "    #lpr_filtered_data_in_minutes_in_this_time_index.columns = np.transpose(['t' + str(i) for i in range(int(ori_max_time_index_sec / group_size))])\n",
    "    df_lpr_min = pd.concat([df_lpr_min, df_lpr_min_in_this_time_index], axis = 1)\n",
    "    \n",
    "    #display(df_lpr_min.head())\n",
    "    #display(df_lpr_min.tail())\n",
    "    \n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print (\"(after  transforming for \" + str(interval) + \"), df_lpr_min.shape:\" + str(df_lpr_min.shape))\n",
    "\n",
    "#print (\"\\nlen(np.unique(df_lpr_min['chemical.id'])):\")\n",
    "#display(len(np.unique(df_lpr_min['chemical.id'])))\n",
    "#print (\"\\nnp.unique(df_lpr_min['chemical.id']):\")\n",
    "#display(np.unique(df_lpr_min['chemical.id']))\n",
    "\n",
    "\n",
    "#lpr_filtered_data_in_minute.head(100) # this should have only 0~23 Tns\n",
    "\n",
    "df_lpr_min['chemical_conc'] = df_lpr_min[['chemical.id','conc']].apply(lambda x: '_'.join(x.map(str)), axis = 1)\n",
    "\n",
    "end_time = time.time()\n",
    "time_took = str(round((end_time-start_time), 1)) + \" seconds\"\n",
    "print (\"Conversion of time interval is done. It took \"+str(time_took))\n",
    "# took 6 seconds for 215 chemicals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_lpr_min.head())\n",
    "display(len(df_lpr_min))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0 concentration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot few lpr curves to check transition points\n",
    "# 0 concentration\n",
    "\n",
    "time_index_start = 4 # because 0-3th columns show irrelevant values (e.g. chemical.id, conc, plate.id, well)\n",
    "\n",
    "df_0_conc       = df_lpr_min.loc[df_lpr_min['conc'] == 0]\n",
    "\n",
    "#print (\"df_0_conc.shape:\" + str(df_0_conc.shape))\n",
    "# chemical.id 414 -> (181, 29)\n",
    "# all 197 chemicals that have 240 variables -> (15718, 29)\n",
    "\n",
    "#print (lpr_min.iloc[:1, time_index_start:time_index_start + num_time_points]) \n",
    "# first ':' shows rows, second ':' shows columns\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(np.transpose(df_0_conc.iloc[10:123,time_index_start:time_index_start + num_time_points].values));\n",
    "#ax.plot(np.transpose(df_0_conc.iloc[:,time_index_start:time_index_start + num_time_points].values));\n",
    "display(len(df_0_conc))\n",
    "display(df_0_conc.head())\n",
    "\n",
    "#ax.plot(np.transpose(df_partial_0_conc.iloc[:,time_index_start:time_index_start + num_time_points].values));\n",
    "#display(len(df_partial_0_conc))\n",
    "#display(df_partial_0_conc.head(10))\n",
    "\n",
    "complete_file_path_basename = os.path.basename(complete_file_path)\n",
    "output_filename_wo_ext = os.path.splitext(complete_file_path_basename)[0]\n",
    "output_filename = output_filename_wo_ext + \"_0_conc.png\"\n",
    "cwd = os.getcwd()\n",
    "print (cwd)\n",
    "print (output_filename)\n",
    "#plt.savefig(output_filename, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# box-whisker plot, mean displacement, dark only\n",
    "column_name = 'y_mean'\n",
    "\n",
    "y_arr = []\n",
    "y_arr.append(np.mean(df_0_conc.iloc[:,7:10], axis = 1).values)\n",
    "y_arr = np.transpose(y_arr)\n",
    "display (y_arr)\n",
    "df_y = pd.DataFrame(y_arr, columns=[column_name])\n",
    "df_y[\"cycle\"] = str(\"1_dark\")\n",
    "############\n",
    "y_arr = []\n",
    "y_arr.append(np.mean(df_0_conc.iloc[:,13:16], axis = 1).values)\n",
    "y_arr = np.transpose(y_arr)\n",
    "df_y_to_concat = pd.DataFrame(y_arr, columns=[column_name])\n",
    "df_y = pd.concat([df_y, df_y_to_concat], axis = 0)\n",
    "df_y['cycle'].fillna('2_dark', inplace=True)\n",
    "############\n",
    "y_arr = []\n",
    "y_arr.append(np.mean(df_0_conc.iloc[:,19:22], axis = 1).values)\n",
    "y_arr = np.transpose(y_arr)\n",
    "df_y_to_concat = pd.DataFrame(y_arr, columns=[column_name])\n",
    "df_y = pd.concat([df_y, df_y_to_concat], axis = 0)\n",
    "df_y['cycle'].fillna('3_dark', inplace=True)\n",
    "############\n",
    "y_arr = []\n",
    "y_arr.append(np.mean(df_0_conc.iloc[:,25:28], axis = 1).values)\n",
    "y_arr = np.transpose(y_arr)\n",
    "df_y_to_concat = pd.DataFrame(y_arr, columns=[column_name])\n",
    "df_y = pd.concat([df_y, df_y_to_concat], axis = 0)\n",
    "df_y['cycle'].fillna('4_dark', inplace=True)\n",
    "################\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "x = \"cycle\"\n",
    "y = column_name\n",
    "order = ['1_dark', '2_dark', '3_dark', '4_dark']\n",
    "ax = sns.boxplot(data=df_y, x=x, y=y, order=order)\n",
    "\n",
    "add_stat_annotation(ax, data=df_y, x=x, y=y, order=order,\n",
    "                    box_pairs=[(\"1_dark\", \"2_dark\"), (\"2_dark\", \"3_dark\"), (\"3_dark\", \"4_dark\")],\n",
    "                    test='Mann-Whitney', text_format='star', loc='outside', verbose=2)\n",
    "\n",
    "plt.title('phase III, 0 conc, mean displacement, dark only')\n",
    "#plt.ylim((0, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# box-whisker plot, total displacement, dark only\n",
    "y_arr = []\n",
    "y_arr.append(df_0_conc.iloc[:,7:10].sum(axis=1).values)\n",
    "y_arr = np.transpose(y_arr)\n",
    "display (y_arr[:5])\n",
    "df_y = pd.DataFrame(y_arr, columns=['y_sum'])\n",
    "df_y[\"cycle\"] = str(\"1_dark\")\n",
    "############\n",
    "y_arr = []\n",
    "y_arr.append(df_0_conc.iloc[:,13:16].sum(axis=1).values)\n",
    "y_arr = np.transpose(y_arr)\n",
    "df_y_to_concat = pd.DataFrame(y_arr, columns=['y_sum'])\n",
    "df_y = pd.concat([df_y, df_y_to_concat], axis = 0)\n",
    "df_y['cycle'].fillna('2_dark', inplace=True)\n",
    "############\n",
    "y_arr = []\n",
    "y_arr.append(df_0_conc.iloc[:,19:22].sum(axis=1).values)\n",
    "y_arr = np.transpose(y_arr)\n",
    "df_y_to_concat = pd.DataFrame(y_arr, columns=['y_sum'])\n",
    "df_y = pd.concat([df_y, df_y_to_concat], axis = 0)\n",
    "df_y['cycle'].fillna('3_dark', inplace=True)\n",
    "############\n",
    "y_arr = []\n",
    "y_arr.append(df_0_conc.iloc[:,25:28].sum(axis=1).values)\n",
    "y_arr = np.transpose(y_arr)\n",
    "df_y_to_concat = pd.DataFrame(y_arr, columns=['y_sum'])\n",
    "df_y = pd.concat([df_y, df_y_to_concat], axis = 0)\n",
    "df_y['cycle'].fillna('4_dark', inplace=True)\n",
    "################\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "x = \"cycle\"\n",
    "y = \"y_sum\"\n",
    "order = ['1_dark', '2_dark', '3_dark', '4_dark']\n",
    "ax = sns.boxplot(data=df_y, x=x, y=y, order=order)#.set_title('lalala')\n",
    "\n",
    "add_stat_annotation(ax, data=df_y, x=x, y=y, order=order,\n",
    "                    box_pairs=[(\"1_dark\", \"2_dark\"), (\"2_dark\", \"3_dark\"), (\"3_dark\", \"4_dark\")],\n",
    "                    test='Mann-Whitney', text_format='star', loc='outside', verbose=2)\n",
    "\n",
    "plt.title('phase III, 0 conc, total displacement, dark only')\n",
    "#plt.ylim((0, 250))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean displacement, light only\n",
    "column_name = 'y_mean'\n",
    "\n",
    "y_arr = []\n",
    "y_arr.append(np.mean(df_0_conc.iloc[:,4:7], axis = 1).values)\n",
    "y_arr = np.transpose(y_arr)\n",
    "display (y_arr[:2])\n",
    "df_y = pd.DataFrame(y_arr, columns=[column_name])\n",
    "df_y[\"cycle\"] = str(\"1_light\")\n",
    "############\n",
    "y_arr = []\n",
    "y_arr.append(np.mean(df_0_conc.iloc[:,10:13], axis = 1).values)\n",
    "y_arr = np.transpose(y_arr)\n",
    "df_y_to_concat = pd.DataFrame(y_arr, columns=[column_name])\n",
    "df_y = pd.concat([df_y, df_y_to_concat], axis = 0)\n",
    "df_y['cycle'].fillna('2_light', inplace=True)\n",
    "############\n",
    "y_arr = []\n",
    "y_arr.append(np.mean(df_0_conc.iloc[:,16:19], axis = 1).values)\n",
    "y_arr = np.transpose(y_arr)\n",
    "df_y_to_concat = pd.DataFrame(y_arr, columns=[column_name])\n",
    "df_y = pd.concat([df_y, df_y_to_concat], axis = 0)\n",
    "df_y['cycle'].fillna('3_light', inplace=True)\n",
    "############\n",
    "y_arr = []\n",
    "y_arr.append(np.mean(df_0_conc.iloc[:,22:25], axis = 1).values)\n",
    "y_arr = np.transpose(y_arr)\n",
    "df_y_to_concat = pd.DataFrame(y_arr, columns=[column_name])\n",
    "df_y = pd.concat([df_y, df_y_to_concat], axis = 0)\n",
    "df_y['cycle'].fillna('4_light', inplace=True)\n",
    "################\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "x = \"cycle\"\n",
    "y = column_name\n",
    "order = ['1_light', '2_light', '3_light', '4_light']\n",
    "ax = sns.boxplot(data=df_y, x=x, y=y, order=order)\n",
    "\n",
    "add_stat_annotation(ax, data=df_y, x=x, y=y, order=order,\n",
    "                    box_pairs=[(\"1_light\", \"2_light\"), (\"2_light\", \"3_light\"), (\"3_light\", \"4_light\")],\n",
    "                    test='Mann-Whitney', text_format='star', loc='outside', verbose=2)\n",
    "\n",
    "plt.title('phase III, 0 conc, mean displacement, light only')\n",
    "plt.ylim((0, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total displacement, light only\n",
    "y_arr = []\n",
    "y_arr.append(df_0_conc.iloc[:,4:7].sum(axis=1).values)\n",
    "y_arr = np.transpose(y_arr)\n",
    "df_y = pd.DataFrame(y_arr, columns=['y_sum'])\n",
    "df_y[\"cycle\"] = str(\"1_light\")\n",
    "############\n",
    "y_arr = []\n",
    "y_arr.append(df_0_conc.iloc[:,10:13].sum(axis=1).values)\n",
    "y_arr = np.transpose(y_arr)\n",
    "df_y_to_concat = pd.DataFrame(y_arr, columns=['y_sum'])\n",
    "df_y = pd.concat([df_y, df_y_to_concat], axis = 0)\n",
    "df_y['cycle'].fillna('2_light', inplace=True)\n",
    "############\n",
    "y_arr = []\n",
    "y_arr.append(df_0_conc.iloc[:,16:19].sum(axis=1).values)\n",
    "y_arr = np.transpose(y_arr)\n",
    "df_y_to_concat = pd.DataFrame(y_arr, columns=['y_sum'])\n",
    "df_y = pd.concat([df_y, df_y_to_concat], axis = 0)\n",
    "df_y['cycle'].fillna('3_light', inplace=True)\n",
    "############\n",
    "y_arr = []\n",
    "y_arr.append(df_0_conc.iloc[:,22:25].sum(axis=1).values)\n",
    "y_arr = np.transpose(y_arr)\n",
    "df_y_to_concat = pd.DataFrame(y_arr, columns=['y_sum'])\n",
    "df_y = pd.concat([df_y, df_y_to_concat], axis = 0)\n",
    "df_y['cycle'].fillna('4_light', inplace=True)\n",
    "################\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "x = \"cycle\"\n",
    "y = \"y_sum\"\n",
    "order = ['1_light', '2_light', '3_light', '4_light']\n",
    "ax = sns.boxplot(data=df_y, x=x, y=y, order=order)\n",
    "add_stat_annotation(ax, data=df_y, x=x, y=y, order=order,\n",
    "                    box_pairs=[(\"1_light\", \"2_light\"), (\"2_light\", \"3_light\"), (\"3_light\", \"4_light\")],\n",
    "                    test='Mann-Whitney', text_format='star', loc='outside', verbose=2)\n",
    "plt.title('phase III, 0 conc, total displacement, light only')\n",
    "plt.ylim((0, 40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# phase III, 0 conc, mean displacement, light & dark\n",
    "column_name = 'y_mean'\n",
    "\n",
    "y_arr = []\n",
    "y_arr.append(np.mean(df_0_conc.iloc[:,4:10], axis = 1).values)\n",
    "y_arr = np.transpose(y_arr)\n",
    "display (y_arr[:2])\n",
    "df_y = pd.DataFrame(y_arr, columns=[column_name])\n",
    "df_y[\"cycle\"] = str(\"1\")\n",
    "############\n",
    "y_arr = []\n",
    "y_arr.append(np.mean(df_0_conc.iloc[:,10:16], axis = 1).values)\n",
    "y_arr = np.transpose(y_arr)\n",
    "df_y_to_concat = pd.DataFrame(y_arr, columns=[column_name])\n",
    "df_y = pd.concat([df_y, df_y_to_concat], axis = 0)\n",
    "df_y['cycle'].fillna('2', inplace=True)\n",
    "############\n",
    "y_arr = []\n",
    "y_arr.append(np.mean(df_0_conc.iloc[:,16:22], axis = 1).values)\n",
    "y_arr = np.transpose(y_arr)\n",
    "df_y_to_concat = pd.DataFrame(y_arr, columns=[column_name])\n",
    "df_y = pd.concat([df_y, df_y_to_concat], axis = 0)\n",
    "df_y['cycle'].fillna('3', inplace=True)\n",
    "############\n",
    "y_arr = []\n",
    "y_arr.append(np.mean(df_0_conc.iloc[:,22:28], axis = 1).values)\n",
    "y_arr = np.transpose(y_arr)\n",
    "df_y_to_concat = pd.DataFrame(y_arr, columns=[column_name])\n",
    "df_y = pd.concat([df_y, df_y_to_concat], axis = 0)\n",
    "df_y['cycle'].fillna('4', inplace=True)\n",
    "################\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "x = \"cycle\"\n",
    "y = column_name\n",
    "order = ['1', '2', '3', '4']\n",
    "ax = sns.boxplot(data=df_y, x=x, y=y, order=order)\n",
    "\n",
    "add_stat_annotation(ax, data=df_y, x=x, y=y, order=order,\n",
    "                    box_pairs=[(\"1\", \"2\"), (\"2\", \"3\"), (\"3\", \"4\")],\n",
    "                    test='Mann-Whitney', text_format='star', loc='outside', verbose=2)\n",
    "\n",
    "plt.title('phase III, 0 conc, light & dark')\n",
    "plt.ylim((0, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total displacement, dark & light\n",
    "y_arr = []\n",
    "y_arr.append(df_0_conc.iloc[:,4:10].sum(axis=1).values)\n",
    "y_arr = np.transpose(y_arr)\n",
    "df_y = pd.DataFrame(y_arr, columns=['y_sum'])\n",
    "df_y[\"cycle\"] = str(\"1\")\n",
    "############\n",
    "y_arr = []\n",
    "y_arr.append(df_0_conc.iloc[:,10:16].sum(axis=1).values)\n",
    "y_arr = np.transpose(y_arr)\n",
    "df_y_to_concat = pd.DataFrame(y_arr, columns=['y_sum'])\n",
    "df_y = pd.concat([df_y, df_y_to_concat], axis = 0)\n",
    "df_y['cycle'].fillna('2', inplace=True)\n",
    "############\n",
    "y_arr = []\n",
    "y_arr.append(df_0_conc.iloc[:,16:22].sum(axis=1).values)\n",
    "y_arr = np.transpose(y_arr)\n",
    "df_y_to_concat = pd.DataFrame(y_arr, columns=['y_sum'])\n",
    "df_y = pd.concat([df_y, df_y_to_concat], axis = 0)\n",
    "df_y['cycle'].fillna('3', inplace=True)\n",
    "############\n",
    "y_arr = []\n",
    "y_arr.append(df_0_conc.iloc[:,22:28].sum(axis=1).values)\n",
    "y_arr = np.transpose(y_arr)\n",
    "df_y_to_concat = pd.DataFrame(y_arr, columns=['y_sum'])\n",
    "df_y = pd.concat([df_y, df_y_to_concat], axis = 0)\n",
    "df_y['cycle'].fillna('4', inplace=True)\n",
    "################\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "x = \"cycle\"\n",
    "y = \"y_sum\"\n",
    "order = ['1', '2', '3', '4']\n",
    "ax = sns.boxplot(data=df_y, x=x, y=y, order=order)\n",
    "add_stat_annotation(ax, data=df_y, x=x, y=y, order=order,\n",
    "                    box_pairs=[(\"1\", \"2\"), (\"2\", \"3\"), (\"3\", \"4\")],\n",
    "                    test='Mann-Whitney', text_format='star', loc='outside', verbose=2)\n",
    "plt.title('phase III, 0 conc, total displacement, light & dark')\n",
    "plt.ylim((0, 250))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[bar plot, dark only]\n",
    "alpha=0.5\n",
    "\n",
    "plt.bar(1, round(np.mean(df_0_conc.iloc[:,7:10].sum(axis=1).values),2),     color ='maroon',width = 0.3, alpha=alpha)\n",
    "plt.bar(2, round(np.mean(df_0_conc.iloc[:,13:16].sum(axis=1).values),2),    color ='red',width = 0.3, alpha=alpha)\n",
    "plt.bar(3, round(np.mean(df_0_conc.iloc[:,19:22].sum(axis=1).values),2),    color ='green',width = 0.3, alpha=alpha)\n",
    "plt.bar(4, round(np.mean(df_0_conc.iloc[:,25:28].sum(axis=1).values),2),    color ='blue',width = 0.3, alpha=alpha)\n",
    "\n",
    "y_arr = []\n",
    "y_arr.append(round(np.mean(df_0_conc.iloc[:,7:10].sum(axis=1).values),2))\n",
    "y_arr.append(round(np.mean(df_0_conc.iloc[:,13:16].sum(axis=1).values),2))\n",
    "y_arr.append(round(np.mean(df_0_conc.iloc[:,19:22].sum(axis=1).values),2))\n",
    "y_arr.append(round(np.mean(df_0_conc.iloc[:,25:28].sum(axis=1).values),2))\n",
    "\n",
    "\n",
    "y_err = []\n",
    "y_err.append(np.std(df_0_conc.iloc[:,7:10].sum(axis=1).values))\n",
    "y_err.append(np.std(df_0_conc.iloc[:,13:16].sum(axis=1).values))\n",
    "y_err.append(np.std(df_0_conc.iloc[:,19:22].sum(axis=1).values))\n",
    "y_err.append(np.std(df_0_conc.iloc[:,25:28].sum(axis=1).values))\n",
    "\n",
    "plt.errorbar([1,2,3,4], y_arr, yerr=y_err, ls='none')\n",
    "\n",
    "plt.title(\"[dark only] maroon->cycle 1, red->cycle 2, green->cycle 3, blue->cycle 4\")\n",
    "plt.xlabel(\"cycle\")\n",
    "plt.ylabel(\"mean\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[bar plot, dark only]\n",
    "\n",
    "print (\"mean:\", round(np.mean(df_0_conc.iloc[:,7:10].sum(axis=1).values),2))\n",
    "print (\"median:\", round(np.median(df_0_conc.iloc[:,7:10].sum(axis=1).values),2))\n",
    "print (\"std:\", round(np.std(df_0_conc.iloc[:,7:10].sum(axis=1).values),2))\n",
    "print (\"max:\", round(np.max(df_0_conc.iloc[:,7:10].sum(axis=1).values),2))\n",
    "print (\"min:\", round(np.min(df_0_conc.iloc[:,7:10].sum(axis=1).values),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[light only]\n",
    "alpha=0.5\n",
    "\n",
    "plt.bar(1, round(np.mean(df_0_conc.iloc[:,4:7].sum(axis=1).values),2),     color ='maroon',width = 0.3, alpha=alpha)\n",
    "plt.bar(2, round(np.mean(df_0_conc.iloc[:,10:13].sum(axis=1).values),2),    color ='red',width = 0.3, alpha=alpha)\n",
    "plt.bar(3, round(np.mean(df_0_conc.iloc[:,16:19].sum(axis=1).values),2),    color ='green',width = 0.3, alpha=alpha)\n",
    "plt.bar(4, round(np.mean(df_0_conc.iloc[:,22:25].sum(axis=1).values),2),    color ='blue',width = 0.3, alpha=alpha)\n",
    "    \n",
    "y_arr = []\n",
    "y_arr.append(round(np.mean(df_0_conc.iloc[:,4:7].sum(axis=1).values),2))\n",
    "y_arr.append(round(np.mean(df_0_conc.iloc[:,10:13].sum(axis=1).values),2))\n",
    "y_arr.append(round(np.mean(df_0_conc.iloc[:,16:19].sum(axis=1).values),2))\n",
    "y_arr.append(round(np.mean(df_0_conc.iloc[:,22:25].sum(axis=1).values),2))\n",
    "\n",
    "y_err = []\n",
    "y_err.append(np.std(df_0_conc.iloc[:,4:7].sum(axis=1).values))\n",
    "y_err.append(np.std(df_0_conc.iloc[:,10:13].sum(axis=1).values))\n",
    "y_err.append(np.std(df_0_conc.iloc[:,16:19].sum(axis=1).values))\n",
    "y_err.append(np.std(df_0_conc.iloc[:,22:25].sum(axis=1).values))\n",
    "\n",
    "plt.errorbar([1,2,3,4], y_arr, yerr=y_err, ls='none')\n",
    "\n",
    "plt.title(\"[light only] maroon->cycle 1, red->cycle 2, green->cycle 3, blue->cycle 4\")\n",
    "plt.xlabel(\"cycle\")\n",
    "plt.ylabel(\"mean\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[light & dark]\n",
    "alpha=0.5\n",
    "\n",
    "display(df_0_conc.iloc[:,4:10].sum(axis=1).values)\n",
    "display(np.mean(df_0_conc.iloc[:,4:10].sum(axis=1).values))\n",
    "display(np.std(df_0_conc.iloc[:,4:10].sum(axis=1).values))\n",
    "\n",
    "plt.bar(1, round(np.mean(df_0_conc.iloc[:,4:10].sum(axis=1).values),2),     color ='maroon',width = 0.3, alpha=alpha)\n",
    "plt.bar(2, round(np.mean(df_0_conc.iloc[:,10:16].sum(axis=1).values),2),    color ='red',width = 0.3, alpha=alpha)\n",
    "plt.bar(3, round(np.mean(df_0_conc.iloc[:,16:22].sum(axis=1).values),2),    color ='green',width = 0.3, alpha=alpha)\n",
    "plt.bar(4, round(np.mean(df_0_conc.iloc[:,22:28].sum(axis=1).values),2),    color ='blue',width = 0.3, alpha=alpha)\n",
    "    \n",
    "y_arr = []\n",
    "y_arr.append(round(np.mean(df_0_conc.iloc[:,4:10].sum(axis=1).values),2))\n",
    "y_arr.append(round(np.mean(df_0_conc.iloc[:,10:16].sum(axis=1).values),2))\n",
    "y_arr.append(round(np.mean(df_0_conc.iloc[:,16:22].sum(axis=1).values),2))\n",
    "y_arr.append(round(np.mean(df_0_conc.iloc[:,22:28].sum(axis=1).values),2))\n",
    "\n",
    "y_err = []\n",
    "y_err.append(np.std(df_0_conc.iloc[:,4:10].sum(axis=1).values))\n",
    "y_err.append(np.std(df_0_conc.iloc[:,10:16].sum(axis=1).values))\n",
    "y_err.append(np.std(df_0_conc.iloc[:,16:22].sum(axis=1).values))\n",
    "y_err.append(np.std(df_0_conc.iloc[:,22:28].sum(axis=1).values))\n",
    "\n",
    "plt.errorbar([1,2,3,4], y_arr, yerr=y_err, ls='none')\n",
    "\n",
    "plt.title(\"[light & dark] maroon->cycle 1, red->cycle 2, green->cycle 3, blue->cycle 4\")\n",
    "plt.xlabel(\"cycle\")\n",
    "plt.ylabel(\"mean\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=0.5\n",
    "\n",
    "plt.bar(\"cycle 1 (2)\", round(np.mean(df_0_conc.iloc[:,7:10].sum(axis=1).values),2),     color ='maroon',width = 0.3, alpha=alpha)\n",
    "plt.bar(\"cycle 2 (8)\", round(np.mean(df_0_conc.iloc[:,13:16].sum(axis=1).values),2),    color ='red',width = 0.3, alpha=alpha)\n",
    "plt.bar(\"cycle 3 (14)\", round(np.mean(df_0_conc.iloc[:,19:22].sum(axis=1).values),2),    color ='green',width = 0.3, alpha=alpha)\n",
    "plt.bar(\"cycle 4 (22)\", round(np.mean(df_0_conc.iloc[:,25:28].sum(axis=1).values),2),    color ='blue',width = 0.3, alpha=alpha)\n",
    "    \n",
    "plt.title(\"[dark only] maroon->cycle 1, red->cycle 2, green->cycle 3, blue->cycle 4\")\n",
    "plt.xlabel(\"transition points\")\n",
    "plt.ylabel(\"mean\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=0.5\n",
    "\n",
    "plt.bar(\"cycle 1 (2)\", round(np.mean(df_0_conc.iloc[:,4:7].sum(axis=1).values),2),     color ='maroon',width = 0.3, alpha=alpha)\n",
    "plt.bar(\"cycle 2 (8)\", round(np.mean(df_0_conc.iloc[:,10:13].sum(axis=1).values),2),    color ='red',width = 0.3, alpha=alpha)\n",
    "plt.bar(\"cycle 3 (14)\", round(np.mean(df_0_conc.iloc[:,16:19].sum(axis=1).values),2),    color ='green',width = 0.3, alpha=alpha)\n",
    "plt.bar(\"cycle 4 (22)\", round(np.mean(df_0_conc.iloc[:,22:25].sum(axis=1).values),2),    color ='blue',width = 0.3, alpha=alpha)\n",
    "    \n",
    "plt.title(\"[light only] maroon->cycle 1, red->cycle 2, green->cycle 3, blue->cycle 4\")\n",
    "plt.xlabel(\"transition points\")\n",
    "plt.ylabel(\"mean\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'''## See sum of y values per interval in all ccp (chemical_conc_plate)\n",
    "#0-6,\n",
    "#6-12,\n",
    "#12-18,\n",
    "#18-24\n",
    "trans_points = [2,8,14,20] # \"Paritosh official\"\n",
    "\n",
    "df_lpr_min_ccp = df_0_conc.copy()\n",
    "#df_lpr_min_ccp = df_partial_0_conc.copy()\n",
    "df_lpr_min_ccp.insert(0, 'chemical_conc_plate', df_0_conc.loc[:,['chemical.id','conc','plate.id']].apply(lambda x: '_'.join(x.map(str)), axis = 1))\n",
    "\n",
    "#f_out = open(\"report.txt\",\"w+\")\n",
    "values_sum_trans_2  = []\n",
    "values_sum_trans_8  = []\n",
    "values_sum_trans_14 = []\n",
    "values_sum_trans_20 = []\n",
    "\n",
    "print (len(np.unique(df_lpr_min_ccp.chemical_conc_plate)))\n",
    "\n",
    "for ccp in np.unique(df_lpr_min_ccp.chemical_conc_plate):\n",
    "    #print (str(ccp))\n",
    "    df_per_ccp = df_lpr_min_ccp.loc[df_lpr_min_ccp.chemical_conc_plate == ccp,:]\n",
    "    #display(df_per_ccp.head())\n",
    "    \n",
    "    for trans_index, trans_point in enumerate(trans_points):\n",
    "        former_timepoints_mean = 999\n",
    "        arr_diff = []\n",
    "        #print (\"\\ntrans_point:\" + str(trans_point))\n",
    "        values_sum_in_this_time_interval = 0\n",
    "        for i in range (-2, 4):\n",
    "            current_timepoint = 't' + str(trans_point+i)\n",
    "            #print (\"current_timepoint:\" + str(current_timepoint))\n",
    "            values = df_per_ccp[current_timepoint]\n",
    "            #print (\"type(values):\\n\" + str(type(values)))\n",
    "            print (\"values:\\n\" + str(values))\n",
    "#            print (\"values.sum():\\n\" + str(values.sum()))\n",
    "            values_sum_in_this_time_interval = values_sum_in_this_time_interval + values.sum()\n",
    "            #print (\"len(values):\\n\" + str(len(values)))\n",
    "            \n",
    "            diff = values.mean() - former_timepoints_mean\n",
    "            arr_diff.append(diff)\n",
    "            former_timepoints_mean = values.mean()\n",
    "        #print (\"arr_diff:\"+str(arr_diff))\n",
    "        print_this = \"values_sum for trans_points \" + str(trans_point) + \" : \" + str(round(values_sum_in_this_time_interval,2))\n",
    "        #print (print_this)\n",
    "        max_diff = max(arr_diff)\n",
    "        index_of_max_diff = arr_diff.index(max_diff)\n",
    "        \n",
    "        unique_ccp = np.unique(df_per_ccp['chemical_conc_plate'])\n",
    "        save_this = unique_ccp[0]\n",
    "        save_this = save_this + \" trans_point: \" + str(trans_point) + \", index_of_max_diff: \" + str(index_of_max_diff) + \"\\n\"\n",
    "        #print (save_this)\n",
    "        \n",
    "        #print (index_of_max_arr_diff)\n",
    "        #f_out.write(save_this)\n",
    "        if (trans_point == 2):\n",
    "            values_sum_trans_2.append(values_sum_in_this_time_interval)\n",
    "        elif (trans_point == 8):\n",
    "             values_sum_trans_8.append(values_sum_in_this_time_interval)\n",
    "        elif (trans_point == 14):\n",
    "            values_sum_trans_14.append(values_sum_in_this_time_interval)\n",
    "        else: # (trans_point == 20):\n",
    "            values_sum_trans_20.append(values_sum_in_this_time_interval)\n",
    "        \n",
    "#f_out.close()\n",
    "print (\"Biggest change of peaks in each ccp is identified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (len(values_sum_trans_2))\n",
    "values_sum_trans_2\n",
    "#print (values_sum_trans_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"\\ntransition points at 2->3 min\")\n",
    "print (\"mean:\", round(np.mean(values_sum_trans_2),2), \", std:\", round(np.std(values_sum_trans_2),2))\n",
    "print (\"median:\", round(np.median(values_sum_trans_2),2))\n",
    "print (\"max:\", round(np.max(values_sum_trans_2),2), \", min:\", round(np.min(values_sum_trans_2),2))\n",
    "\n",
    "print (\"\\ntransition points at 8->9 min\")\n",
    "#print (\"arr_max_index_per_trans_8:\" + str(arr_max_index_per_trans_8))\n",
    "print (\"mean:\", round(np.mean(values_sum_trans_8),2), \", std:\", round(np.std(values_sum_trans_8),2))\n",
    "print (\"median:\", round(np.median(values_sum_trans_8),2))\n",
    "print (\"max:\", round(np.max(values_sum_trans_8),2), \", min:\", round(np.min(values_sum_trans_8),2))\n",
    "\n",
    "print (\"\\ntransition points at 14->15 min\")\n",
    "print (\"mean:\", round(np.mean(values_sum_trans_14),2), \", std:\", round(np.std(values_sum_trans_14),2))\n",
    "print (\"median:\", round(np.median(values_sum_trans_14),2))\n",
    "print (\"max:\", round(np.max(values_sum_trans_14),2), \", min:\", round(np.min(values_sum_trans_14),2))\n",
    "\n",
    "print (\"\\ntransition points at 20->21 min\")\n",
    "print (\"mean:\", round(np.mean(values_sum_trans_20),2), \", std:\", round(np.std(values_sum_trans_20),2))\n",
    "print (\"median:\", round(np.median(values_sum_trans_20),2))\n",
    "print (\"max:\", round(np.max(values_sum_trans_20),2), \", min:\", round(np.min(values_sum_trans_20),2))\n",
    "\n",
    "alpha=0.5\n",
    "\n",
    "plt.bar(\"2\", round(np.mean(values_sum_trans_2),2),     color ='maroon',width = 0.3, alpha=alpha)\n",
    "plt.bar(\"8\", round(np.mean(values_sum_trans_8),2),     color ='red',   width = 0.3, alpha=alpha)\n",
    "plt.bar(\"14\", round(np.mean(values_sum_trans_14),2),   color ='green', width = 0.3, alpha=alpha)\n",
    "plt.bar(\"20\", round(np.mean(values_sum_trans_20),2),   color ='blue',  width = 0.3, alpha=alpha)\n",
    "    \n",
    "plt.title(\"maroon->2, red->8, green->14, blue->20\")\n",
    "plt.xlabel(\"transition points\")\n",
    "plt.ylabel(\"mean\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.bar(\"2\", round(np.std(values_sum_trans_2),2),     color ='maroon',width = 0.3, alpha=alpha)\n",
    "plt.bar(\"8\", round(np.std(values_sum_trans_8),2),     color ='red',   width = 0.3, alpha=alpha)\n",
    "plt.bar(\"14\", round(np.std(values_sum_trans_14),2),   color ='green', width = 0.3, alpha=alpha)\n",
    "plt.bar(\"20\", round(np.std(values_sum_trans_20),2),   color ='blue',  width = 0.3, alpha=alpha)\n",
    "    \n",
    "plt.title(\"maroon->2, red->8, green->14, blue->20\")\n",
    "plt.xlabel(\"transition points\")\n",
    "plt.ylabel(\"std\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.bar(\"2\", round(np.max(values_sum_trans_2),2),     color ='maroon',width = 0.3, alpha=alpha)\n",
    "plt.bar(\"8\", round(np.max(values_sum_trans_8),2),     color ='red',   width = 0.3, alpha=alpha)\n",
    "plt.bar(\"14\", round(np.max(values_sum_trans_14),2),   color ='green', width = 0.3, alpha=alpha)\n",
    "plt.bar(\"20\", round(np.max(values_sum_trans_20),2),   color ='blue',  width = 0.3, alpha=alpha)\n",
    "    \n",
    "plt.title(\"maroon->2, red->8, green->14, blue->20\")\n",
    "plt.xlabel(\"transition points\")\n",
    "plt.ylabel(\"max\")\n",
    "plt.show()\n",
    "\n",
    "plt.bar(\"2\", round(np.min(values_sum_trans_2),2),     color ='maroon',width = 0.3, alpha=alpha)\n",
    "plt.bar(\"8\", round(np.min(values_sum_trans_8),2),     color ='red',   width = 0.3, alpha=alpha)\n",
    "plt.bar(\"14\", round(np.min(values_sum_trans_14),2),   color ='green', width = 0.3, alpha=alpha)\n",
    "plt.bar(\"20\", round(np.min(values_sum_trans_20),2),   color ='blue',  width = 0.3, alpha=alpha)\n",
    "    \n",
    "plt.title(\"maroon->2, red->8, green->14, blue->20\")\n",
    "plt.xlabel(\"transition points\")\n",
    "plt.ylabel(\"min\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lpr_min.get_value(10, 't1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "boxplot = df_lpr_min.boxplot(column=['t1', 't2', 't3', 't4', 't5', 't6'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "boxplot = df_lpr_min.boxplot(column=['t7', 't8', 't9', 't10', 't11', 't12'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "boxplot = df_lpr_min.boxplot(column=['t13', 't14', 't15', 't16', 't17', 't18'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "boxplot = df_lpr_min.boxplot(column=['t19', 't20', 't21', 't22', 't23'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(len(df_lpr_min_ccp))\n",
    "display(df_lpr_min_ccp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### stop here\n",
    "a=b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculate MOV, AUC for 0 chemical concentration only\n",
    "\n",
    "df_delta_0_conc = df_lpr_min_0_conc[['chemical.id', 'conc', 'plate.id', 'well']].copy()\n",
    "#'delta' was 'delta_mov_auc'\n",
    "\n",
    "trans_points = [2,8,14,20] # \"official\"\n",
    "#trans_points = [2,8,15,21]\n",
    "end_points = ['MOV', 'AUC']\n",
    "\n",
    "num_light = 3 # seems reasonable since interval between middle points of each peak ~= 6\n",
    "num_dark  = 3\n",
    "\n",
    "for trans_index, trans_point in enumerate(trans_points):\n",
    "    for just_index, end_point in enumerate(end_points):\n",
    "        if (end_point == 'MOV'):\n",
    "            delta_0_conc['MOV' + str(trans_index + 1)] \\\n",
    "            = lpr_min['t' + str(trans_point + 1)] \\\n",
    "            - lpr_min['t' + str(trans_point)]\n",
    "        else:\n",
    "            delta_0_conc['AUC' + str(trans_index + 1)] \\\n",
    "            = sum(lpr_min['t' + str(trans_point + 1 + index_count)] \\\n",
    "                  for index_count in range(num_dark)) \\\n",
    "            - sum(lpr_min['t' + str(trans_point - index_count)] \\\n",
    "                  for index_count in range(num_light))\n",
    "        \n",
    "display(delta_0_conc.head(1))\n",
    "delta_0_conc.to_csv(\"delta_mov_auc_0_conc.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## investigate whether AUC4 is negative\n",
    "\n",
    "AUC1_mean_neg = AUC1_mean_pos = AUC2_mean_neg = AUC2_mean_pos = 0\n",
    "AUC3_mean_neg = AUC3_mean_pos = AUC4_mean_neg = AUC4_mean_pos = 0\n",
    "\n",
    "unique_chemical_id_s = np.unique(delta_0_conc['chemical.id'])\n",
    "print (len(unique_chemical_id_s))\n",
    "for i in range(len(unique_chemical_id_s)):\n",
    "    chemical_id = unique_chemical_id_s[i]\n",
    "    #if (chemical_id != 414):\n",
    "    #    continue\n",
    "    #print (\"\\n\", chemical_id)\n",
    "    per_chemical = delta_0_conc.loc[delta_0_conc['chemical.id'] == chemical_id]\n",
    "    #display(per_chemical)\n",
    "    #display(per_chemical[\"AUC4\"].mean())\n",
    "\n",
    "    AUC1_mean = float(per_chemical[\"AUC1\"].mean())\n",
    "    if (AUC1_mean) < 0:\n",
    "        AUC1_mean_neg += 1\n",
    "    else:\n",
    "        AUC1_mean_pos += 1\n",
    "            \n",
    "    AUC2_mean = float(per_chemical[\"AUC2\"].mean())\n",
    "    if (AUC2_mean) < 0:\n",
    "        AUC2_mean_neg += 1\n",
    "    else:\n",
    "        AUC2_mean_pos += 1\n",
    "        \n",
    "    AUC3_mean = float(per_chemical[\"AUC3\"].mean())\n",
    "    if (AUC3_mean) < 0:\n",
    "        AUC3_mean_neg += 1\n",
    "    else:\n",
    "        AUC3_mean_pos += 1\n",
    "\n",
    "    AUC4_mean = float(per_chemical[\"AUC4\"].mean())\n",
    "    if (AUC4_mean) < 0:\n",
    "        AUC4_mean_neg += 1\n",
    "    else:\n",
    "        AUC4_mean_pos += 1\n",
    "\n",
    "display(AUC1_mean_pos) # 100\n",
    "display(AUC1_mean_neg) # 1\n",
    "\n",
    "display(AUC2_mean_pos) # 100\n",
    "display(AUC2_mean_neg) # 1\n",
    "\n",
    "display(AUC3_mean_pos) # 100\n",
    "display(AUC3_mean_neg) # 1\n",
    "\n",
    "display(AUC4_mean_pos) # 62\n",
    "display(AUC4_mean_neg) # 39\n",
    "#display(AUC4_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\"before dropna, len(df_lpr_filtered):\"+str(len(df_lpr_filtered)))\n",
    "df_lpr_filtered_no_na = df_lpr_filtered.dropna(how='any')\n",
    "display(\"after dropna,  len(df_lpr_filtered_no_na):\"+str(len(df_lpr_filtered_no_na)))\n",
    "\n",
    "is_NaN = df_lpr_filtered.isnull()\n",
    "row_has_NaN = is_NaN.any(axis=1)\n",
    "rows_with_NaN = df_lpr_filtered[row_has_NaN]\n",
    "\n",
    "display(rows_with_NaN.head())\n",
    "display(len(rows_with_NaN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_lpr.to_csv(\"df_lpr_cpw_added.csv\",index=False)\n",
    "df_lpr_filtered.to_csv(\"df_lpr_filtered_cpw_added.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_lpr_filtered_no_na.head())\n",
    "\n",
    "print (\"df_lpr_filtered_no_na.shape:\" + str(df_lpr_filtered_no_na.shape))\n",
    "#(8160610, 7)\n",
    "\n",
    "#display(len(lpr_filtered_data))\n",
    "#lpr_filtered_data.to_csv(\"lpr_filtered_data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip this\n",
    "\"(Lisa) LPR (5d): L1: T61-89; D1: T90-119; L2: T120-149; D2: T150-179; L3: T180-209; D3: T210-239\"\n",
    "\n",
    "# (L0,D0) \n",
    "# T1 - T60 --> 360 seconds -> 6 minutes\n",
    "\n",
    "# (L1,D1) \n",
    "# T61 - T120 --> 360 seconds -> 6 minutes\n",
    "\n",
    "# (L2,D2) \n",
    "# T121 - T180 --> 360 seconds -> 6 minutes\n",
    "\n",
    "# (L3,D3) \n",
    "# T181 - T240 --> 360 seconds -> 6 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate new decreasing endpoints\n",
    "delta_mov_auc_w_decreasing = delta_mov_auc.copy()\n",
    "for transition_index, transition_point in enumerate(transition_points):\n",
    "    print (\"\\ntransition_index:\" + str(transition_index))\n",
    "    print (\"transition_point:\" + str(transition_point))\n",
    "    \n",
    "    for just_index, end_point in enumerate(end_points):\n",
    "        ori = str(end_point) + str(transition_index + 1)\n",
    "        #print (\"\\nori:\" + str(ori))\n",
    "        #print (\"delta_mov_auc_w_decreasing[ori]:\\n\" + str(delta_mov_auc_w_decreasing[ori]))\n",
    "        \n",
    "        for new_index in range(len(transition_points)-1):\n",
    "            final_index = transition_index + new_index\n",
    "            new = str(end_point) + str(final_index+2)\n",
    "            #print (\"new:\" + str(new))\n",
    "            check_whether_new_exists = new in delta_mov_auc_w_decreasing.columns\n",
    "            #print (\"check_whether_new_exists:\"+str(check_whether_new_exists))\n",
    "            if (check_whether_new_exists == False):\n",
    "                continue\n",
    "            name = str(end_point) + str(transition_index + 1) + \"_\" + str(new)\n",
    "            print (\"name:\" + str(name))\n",
    "            delta_mov_auc_w_decreasing[name] \\\n",
    "                = delta_mov_auc_w_decreasing[ori] - delta_mov_auc_w_decreasing[new]\n",
    "display (delta_mov_auc_w_decreasing.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate final decreasing endpoints\n",
    "delta_mov_auc_w_decreasing_copied = delta_mov_auc_w_decreasing.copy()\n",
    "delta_mov_auc_final = delta_mov_auc_w_decreasing.copy()\n",
    "columns_to_keep = []\n",
    "for just_index, end_point in enumerate(end_points):\n",
    "    for (columnName, columnData) in delta_mov_auc_w_decreasing_copied.iteritems():\n",
    "        if \"_\" not in columnName:\n",
    "            continue\n",
    "        if str(end_point) not in columnName:\n",
    "            continue\n",
    "#        print('Colunm Name : ', columnName)\n",
    "        columns_to_keep.append(columnName)\n",
    "\n",
    "    delta_mov_auc_w_decreasing_copied_select = delta_mov_auc_w_decreasing_copied.loc[:,columns_to_keep]\n",
    "    \n",
    "    # \"axis 0” represents rows\n",
    "    # \"axis 1” represents columns\n",
    "\n",
    "    all_ = delta_mov_auc_w_decreasing_copied_select.sum(axis=1)\n",
    "   # print (\"all_:\\n\" + str(all_))\n",
    "    \n",
    "    final_endpoint_name = str(end_point) + \"_all_\" \n",
    "    delta_mov_auc_final.insert(0, final_endpoint_name, all_)\n",
    "    \n",
    "\n",
    "display(\"delta_mov_auc_final.head():\", delta_mov_auc_final.head())\n",
    "    \n",
    "delta_mov_auc_final.to_csv(\"delta_mov_auc_final.csv\",index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename column headers to make it compatible with earlier data received from Lisa\n",
    "delta_mov_auc.rename(columns={\"chemical.id\": \"Chemical.ID\", \"conc\": \"CONC\", \"plate.id\": \"Plate\", \"well\": \"WELL\"}, inplace = True)\n",
    "display(delta_mov_auc.head())\n",
    "#display(delta_mov_auc.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import generate_dose_response as gdr\n",
    "import BMD_BMDL_estimation as bmdest\n",
    "import Plot_Save as ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "os.chdir(starting_dir)\n",
    "\n",
    "if (os.path.isdir(\"output\") == True):\n",
    "    shutil.rmtree(\"output\")\n",
    "os.mkdir(\"output\")\n",
    "\n",
    "output_folder = os.path.join(starting_dir, \"output\")\n",
    "os.chdir(output_folder)\n",
    "\n",
    "full_devel = \"full\"\n",
    "#full_devel = \"devel\"\n",
    "\n",
    "if (full_devel == \"full\"):\n",
    "    chemical_id_from_here = np.unique(delta_mov_auc['Chemical.ID'])\n",
    "    end_points_from_here = ['MOV1','AUC1']\n",
    "else:\n",
    "    chemical_id_from_here = [53]\n",
    "    end_points_from_here = ['MOV1']\n",
    "\n",
    "#report = True\n",
    "report = False\n",
    "\n",
    "for chemical_id in chemical_id_from_here:\n",
    "    if (report): print(\"chemical_id:\" + str(chemical_id))\n",
    "    for end_point in end_points_from_here:\n",
    "        if (report): print(\"end_point:\" + str(end_point))\n",
    "        # subset original dataframe for a user-specified chemical and end_point pair\n",
    "        delta_mov_auc_end_point_chemical_id = delta_mov_auc.loc[delta_mov_auc['Chemical.ID'] == chemical_id,['Chemical.ID', 'CONC', 'Plate', 'WELL', end_point]]\n",
    "        #print(\"delta_mov_auc_end_point_chemical_id:\\n\"+str(delta_mov_auc_end_point_chemical_id))\n",
    "        #print(\"type(delta_mov_auc_end_point_chemical_id):\\n\"+str(type(delta_mov_auc_end_point_chemical_id)))\n",
    "        #print(\"type(end_point):\\n\"+str(type(end_point)))\n",
    "\n",
    "        dose_response = gdr.gen_dose_response_behavior(delta_mov_auc_end_point_chemical_id, end_point)\n",
    "        if (report): print(\"dose_response:\\n\"+str(dose_response))\n",
    "        qc_flag = gdr.BMD_feasibility_analysis(dose_response)\n",
    "        test_dose_response = gdr.reformat_dose_response(dose_response)\n",
    "        #test_dose_response = dose_response\n",
    "        if(qc_flag in [0, 1]):\n",
    "            # No BMD analysis required. Generate report and exit\n",
    "            ps.save_results_poor_data_or_no_convergence(test_dose_response, qc_flag, str(chemical_id), end_point, None)\n",
    "        else:\n",
    "            # Fit dose response models\n",
    "            model_predictions = bmdest.analyze_dose_response_data(test_dose_response)\n",
    "            # Select best model\n",
    "            selected_model_params = bmdest.select_model(model_predictions)\n",
    "            # Check if unique model is found\n",
    "            unique_model_flag = selected_model_params['no_unique_model_found_flag']\n",
    "            if(unique_model_flag == 0):\n",
    "                # Generate report\n",
    "                ps.save_results_good_data_unique_model(test_dose_response, qc_flag, model_predictions, selected_model_params, str(chemical_id), end_point)\n",
    "            else:\n",
    "                bmd_analysis_flag = selected_model_params['model_select_flag']\n",
    "                if(bmd_analysis_flag == 1):\n",
    "                    ps.save_results_poor_data_or_no_convergence(test_dose_response, qc_flag, str(chemical_id), end_point, selected_model_params)\n",
    "                else:\n",
    "                    ps.save_results_good_data_nounique_model(test_dose_response, qc_flag, model_predictions, selected_model_params, str(chemical_id), end_point)\n",
    "end_time = time.time()\n",
    "time_took = str(round((end_time-start_time), 1)) + \" seconds\"\n",
    "print (\"Done, it took:\"+str(time_took))\n",
    "# 1 chemical (3756) and 2 endpoints (['MOV1','AUC1']), 140 seconds took\n",
    "# 7 chemicals and 2 endpoints (['MOV1','AUC1']), 6 minutes took\n",
    "\n",
    "time_filename = 'running_time.txt'\n",
    "f_time = open(time_filename, 'w')\n",
    "f_time.write(str(time_took))\n",
    "f_time.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
